{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the use of Optical Character Recognition (OCR)\n",
    "\n",
    "It has become clear very quickly that we actually need Handwriting Recognition (HWR), not OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('flagged/img/tmp07b_1pop.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pytesseract.image_to_string(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADgAAAA4CAYAAACohjseAAACmUlEQVR4nO2Zu6ryQBSF14wGBVFQLAx4QRAbC99CsLKwsdYHEXwFe2t9DV9BsRZsbFJYKCjoPpX+v7eJyew5MYd8kMa5reXek51JBBER/jAyaAGmiQyGnchg2IkMhp3IYNiJDIadyGDY+SqDs9kMtm0jl8uh0+nwTEpfQrPZJAB3V6FQ0J5XEAV/HrRtG9vt9mXbbrdDJpPxPXfgKSqlfGsOACaTidb8gUZQCKFsbzQaWC6XWmuwRrDf7yOZTGKxWLgvLNVLJxIJbXMAUwQ3mw3K5fL9xELgcrm87J9KpXA4HN6LUoz1CksEq9Xq029EBCEE5vP53e+/ae4qRBs83N4fr3K5TEREpVJJ2c+yLA45d7CkqJQSbtPEYjGcz2dlHwYpT7CkaDabde0ThDmAyaDjOFiv1663/XeYMgcwlolKpYLL5eJZbLfb5ZLwEmOF/pNo5nI5OI5jYvl/OkwZTCaTOB6Pyj4mU/OKkWfR4XDoag74LMq6GImgF+Hshf0B9gi6PWM+QkRIpVLcMm6wGozH47721eFwQKPR4JRyg81gq9VSFnMppTJ1V6sVBoMBl5wbbHvQbd9dl/m0HxcsEXTbd/+LdjPgdQ+7oT1bOp1Win71ykHVn4iQz+d1Zd1NqAUUx598Pv92XL1eV47lQmsPqo5Jn9S3d4dfy7JwOp38yrrX6HdgIpFQptonxXu/3z+96gCAdrvtV9YzfkMPxvSq1WokpSQpJfV6Pb+SXuIrRXVT8zfxlaKq/+SbzAE+DKrqlGVZWmJM4DlFVU8iPrLdOJ4iWCwWfbUFiSeD4/H4bdtms9EWYwSvt128KAuj0Yj11s6JZ4PT6ZSEEDdzsVjMhC42vuIDqEkC/wBqmshg2IkMhp0/b/AHYIFt8QS5a3MAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=56x56>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Sketchpad in module gradio.templates:\n",
      "\n",
      "class Sketchpad(gradio.components.Image)\n",
      " |  Sketchpad(value: 'str | Image | np.ndarray | None' = None, *, shape: 'tuple[int, int]' = (28, 28), image_mode: 'str' = 'L', invert_colors: 'bool' = True, source: 'str' = 'canvas', tool: 'str | None' = None, type: 'str' = 'numpy', label: 'str | None' = None, show_label: 'bool' = True, interactive: 'bool | None' = True, visible: 'bool' = True, streaming: 'bool' = False, elem_id: 'str | None' = None, mirror_webcam: 'bool' = True, brush_radius: 'float | None' = None, **kwargs)\n",
      " |  \n",
      " |  Sets: image_mode=\"L\", source=\"canvas\", shape=(28, 28), invert_colors=True, interactive=True\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Sketchpad\n",
      " |      gradio.components.Image\n",
      " |      gradio.events.Editable\n",
      " |      gradio.events.Clearable\n",
      " |      gradio.events.Changeable\n",
      " |      gradio.events.Streamable\n",
      " |      gradio.events.Selectable\n",
      " |      gradio.events.Uploadable\n",
      " |      gradio.events.EventListener\n",
      " |      gradio.components.IOComponent\n",
      " |      gradio.components.Component\n",
      " |      gradio.blocks.Block\n",
      " |      gradio_client.serializing.ImgSerializable\n",
      " |      gradio_client.serializing.Serializable\n",
      " |      gradio.interpretation.TokenInterpretable\n",
      " |      gradio.interpretation.Interpretable\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, value: 'str | Image | np.ndarray | None' = None, *, shape: 'tuple[int, int]' = (28, 28), image_mode: 'str' = 'L', invert_colors: 'bool' = True, source: 'str' = 'canvas', tool: 'str | None' = None, type: 'str' = 'numpy', label: 'str | None' = None, show_label: 'bool' = True, interactive: 'bool | None' = True, visible: 'bool' = True, streaming: 'bool' = False, elem_id: 'str | None' = None, mirror_webcam: 'bool' = True, brush_radius: 'float | None' = None, **kwargs)\n",
      " |      Parameters:\n",
      " |          value: A PIL Image, numpy array, path or URL for the default value that Image component is going to take. If callable, the function will be called whenever the app loads to set the initial value of the component.\n",
      " |          shape: (width, height) shape to crop and resize image to; if None, matches input image size. Pass None for either width or height to only crop and resize the other.\n",
      " |          image_mode: \"RGB\" if color, or \"L\" if black and white.\n",
      " |          invert_colors: whether to invert the image as a preprocessing step.\n",
      " |          source: Source of image. \"upload\" creates a box where user can drop an image file, \"webcam\" allows user to take snapshot from their webcam, \"canvas\" defaults to a white image that can be edited and drawn upon with tools.\n",
      " |          tool: Tools used for editing. \"editor\" allows a full screen editor (and is the default if source is \"upload\" or \"webcam\"), \"select\" provides a cropping and zoom tool, \"sketch\" allows you to create a binary sketch (and is the default if source=\"canvas\"), and \"color-sketch\" allows you to created a sketch in different colors. \"color-sketch\" can be used with source=\"upload\" or \"webcam\" to allow sketching on an image. \"sketch\" can also be used with \"upload\" or \"webcam\" to create a mask over an image and in that case both the image and mask are passed into the function as a dictionary with keys \"image\" and \"mask\" respectively.\n",
      " |          type: The format the image is converted to before being passed into the prediction function. \"numpy\" converts the image to a numpy array with shape (height, width, 3) and values from 0 to 255, \"pil\" converts the image to a PIL image object, \"filepath\" passes a str path to a temporary file containing the image.\n",
      " |          label: component name in interface.\n",
      " |          every: If `value` is a callable, run the function 'every' number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component's .load_event attribute.\n",
      " |          show_label: if True, will display label.\n",
      " |          interactive: if True, will allow users to upload and edit an image; if False, can only be used to display images. If not provided, this is inferred based on whether the component is used as an input or output.\n",
      " |          visible: If False, component will be hidden.\n",
      " |          streaming: If True when used in a `live` interface, will automatically stream webcam feed. Only valid is source is 'webcam'.\n",
      " |          elem_id: An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.\n",
      " |          elem_classes: An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.\n",
      " |          mirror_webcam: If True webcam will be mirrored. Default is True.\n",
      " |          brush_radius: Size of the brush for Sketch. Default is None which chooses a sensible default\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  is_template = True\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gradio.components.Image:\n",
      " |  \n",
      " |  as_example(self, input_data: 'str | None') -> 'str'\n",
      " |      Return the input data in a way that can be displayed by the examples dataset component in the front-end.\n",
      " |  \n",
      " |  check_streamable(self)\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      :return: a dictionary with context variables for the javascript file associated with the context\n",
      " |  \n",
      " |  get_interpretation_scores(self, x, neighbors, scores, masks, tokens=None, **kwargs) -> 'list[list[float]]'\n",
      " |      Returns:\n",
      " |          A 2D array representing the interpretation score of each pixel of the image.\n",
      " |  \n",
      " |  get_masked_inputs(self, tokens, binary_mask_matrix)\n",
      " |  \n",
      " |  postprocess(self, y: 'np.ndarray | _Image.Image | str | Path | None') -> 'str | None'\n",
      " |      Parameters:\n",
      " |          y: image as a numpy array, PIL Image, string/Path filepath, or string URL\n",
      " |      Returns:\n",
      " |          base64 url data\n",
      " |  \n",
      " |  preprocess(self, x: 'str | dict[str, str]') -> 'np.ndarray | _Image.Image | str | dict | None'\n",
      " |      Parameters:\n",
      " |          x: base64 url data, or (if tool == \"sketch\") a dict of image and mask base64 url data\n",
      " |      Returns:\n",
      " |          image in requested format, or (if tool == \"sketch\") a dict of image and mask in requested format\n",
      " |  \n",
      " |  set_interpret_parameters(self, segments: 'int' = 16)\n",
      " |      Calculates interpretation score of image subsections by splitting the image into subsections, then using a \"leave one out\" method to calculate the score of each subsection by whiting out the subsection and measuring the delta of the output value.\n",
      " |      Parameters:\n",
      " |          segments: Number of interpretation segments to split image into.\n",
      " |  \n",
      " |  style(self, *, height: 'int | None' = None, width: 'int | None' = None, **kwargs)\n",
      " |      This method can be used to change the appearance of the Image component.\n",
      " |      Parameters:\n",
      " |          height: Height of the image.\n",
      " |          width: Width of the image.\n",
      " |  \n",
      " |  tokenize(self, x)\n",
      " |      Segments image into tokens, masks, and leave-one-out-tokens\n",
      " |      Parameters:\n",
      " |          x: base64 representation of an image\n",
      " |      Returns:\n",
      " |          tokens: list of tokens, used by the get_masked_input() method\n",
      " |          leave_one_out_tokens: list of left-out tokens, used by the get_interpretation_neighbors() method\n",
      " |          masks: list of masks, used by the get_interpretation_neighbors() method\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from gradio.components.Image:\n",
      " |  \n",
      " |  update(value: 'Any | Literal[_Keywords.NO_VALUE] | None' = <_Keywords.NO_VALUE: 'NO_VALUE'>, label: 'str | None' = None, show_label: 'bool | None' = None, interactive: 'bool | None' = None, visible: 'bool | None' = None, brush_radius: 'float | None' = None)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gradio.components.IOComponent:\n",
      " |  \n",
      " |  attach_load_event(self, callable: 'Callable', every: 'float | None')\n",
      " |      Add a load event that runs `callable`, optionally every `every` seconds.\n",
      " |  \n",
      " |  audio_to_temp_file(self, data: 'np.ndarray', sample_rate: 'int', dir: 'str', format: 'str')\n",
      " |  \n",
      " |  base64_to_temp_file_if_needed(self, base64_encoding: 'str', file_name: 'str | None' = None) -> 'str'\n",
      " |      Converts a base64 encoding to a file and returns the path to the file if\n",
      " |      the file doesn't already exist. Otherwise returns the path to the existing file.\n",
      " |  \n",
      " |  download_temp_copy_if_needed(self, url: 'str') -> 'str'\n",
      " |      Downloads a file and makes a temporary file path for a copy if does not already\n",
      " |      exist. Otherwise returns the path to the existing temp file.\n",
      " |  \n",
      " |  file_bytes_to_file(self, data: 'bytes', dir: 'str', file_name: 'str')\n",
      " |  \n",
      " |  img_array_to_temp_file(self, arr: 'np.ndarray', dir: 'str') -> 'str'\n",
      " |  \n",
      " |  make_temp_copy_if_needed(self, file_path: 'str') -> 'str'\n",
      " |      Returns a temporary file path for a copy of the given file path if it does\n",
      " |      not already exist. Otherwise returns the path to the existing temp file.\n",
      " |  \n",
      " |  pil_to_temp_file(self, img: '_Image.Image', dir: 'str', format='png') -> 'str'\n",
      " |  \n",
      " |  async save_uploaded_file(self, file: 'UploadFile', upload_dir: 'str') -> 'str'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from gradio.components.IOComponent:\n",
      " |  \n",
      " |  get_load_fn_and_initial_value(value)\n",
      " |  \n",
      " |  hash_base64(base64_encoding: 'str', chunk_num_blocks: 'int' = 128) -> 'str'\n",
      " |  \n",
      " |  hash_bytes(bytes: 'bytes')\n",
      " |  \n",
      " |  hash_file(file_path: 'str', chunk_num_blocks: 'int' = 128) -> 'str'\n",
      " |  \n",
      " |  hash_url(url: 'str', chunk_num_blocks: 'int' = 128) -> 'str'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gradio.components.Component:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gradio.blocks.Block:\n",
      " |  \n",
      " |  get_block_name(self) -> 'str'\n",
      " |      Gets block's class name.\n",
      " |      \n",
      " |      If it is template component it gets the parent's class name.\n",
      " |      \n",
      " |      @return: class name\n",
      " |  \n",
      " |  get_expected_parent(self) -> 'type[BlockContext] | None'\n",
      " |  \n",
      " |  render(self)\n",
      " |      Adds self into appropriate BlockContext\n",
      " |  \n",
      " |  set_event_trigger(self, event_name: 'str', fn: 'Callable | None', inputs: 'Component | list[Component] | set[Component] | None', outputs: 'Component | list[Component] | None', preprocess: 'bool' = True, postprocess: 'bool' = True, scroll_to_output: 'bool' = False, show_progress: 'bool' = True, api_name: 'str | None' = None, js: 'str | None' = None, no_target: 'bool' = False, queue: 'bool | None' = None, batch: 'bool' = False, max_batch_size: 'int' = 4, cancels: 'list[int] | None' = None, every: 'float | None' = None, collects_event_data: 'bool | None' = None, trigger_after: 'int | None' = None, trigger_only_on_success: 'bool' = False) -> 'tuple[dict[str, Any], int]'\n",
      " |      Adds an event to the component's dependencies.\n",
      " |      Parameters:\n",
      " |          event_name: event name\n",
      " |          fn: Callable function\n",
      " |          inputs: input list\n",
      " |          outputs: output list\n",
      " |          preprocess: whether to run the preprocess methods of components\n",
      " |          postprocess: whether to run the postprocess methods of components\n",
      " |          scroll_to_output: whether to scroll to output of dependency on trigger\n",
      " |          show_progress: whether to show progress animation while running.\n",
      " |          api_name: Defining this parameter exposes the endpoint in the api docs\n",
      " |          js: Experimental parameter (API may change): Optional frontend js method to run before running 'fn'. Input arguments for js method are values of 'inputs' and 'outputs', return should be a list of values for output components\n",
      " |          no_target: if True, sets \"targets\" to [], used for Blocks \"load\" event\n",
      " |          queue: If True, will place the request on the queue, if the queue has been enabled. If False, will not put this event on the queue, even if the queue has been enabled. If None, will use the queue setting of the gradio app.\n",
      " |          batch: whether this function takes in a batch of inputs\n",
      " |          max_batch_size: the maximum batch size to send to the function\n",
      " |          cancels: a list of other events to cancel when this event is triggered. For example, setting cancels=[click_event] will cancel the click_event, where click_event is the return value of another components .click method.\n",
      " |          every: Run this event 'every' number of seconds while the client connection is open. Interpreted in seconds. Queue must be enabled.\n",
      " |          collects_event_data: whether to collect event data for this event\n",
      " |          trigger_after: if set, this event will be triggered after 'trigger_after' function index\n",
      " |          trigger_only_on_success: if True, this event will only be triggered if the previous event was successful (only applies if `trigger_after` is set)\n",
      " |      Returns: dependency information, dependency index\n",
      " |  \n",
      " |  unrender(self)\n",
      " |      Removes self from BlockContext if it has been rendered (otherwise does nothing).\n",
      " |      Removes self from the layout and collection of blocks, but does not delete any event triggers.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from gradio.blocks.Block:\n",
      " |  \n",
      " |  get_specific_update(generic_update: 'dict[str, Any]') -> 'dict' from abc.ABCMeta\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gradio.blocks.Block:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gradio_client.serializing.ImgSerializable:\n",
      " |  \n",
      " |  api_info(self) -> 'dict[str, bool | dict]'\n",
      " |      The typing information for this component as a dictionary whose values are a list of 2 strings: [Python type, language-agnostic description].\n",
      " |      Keys of the dictionary are: raw_input, raw_output, serialized_input, serialized_output\n",
      " |  \n",
      " |  deserialize(self, x: 'str | None', save_dir: 'str | Path | None' = None, root_url: 'str | None' = None, hf_token: 'str | None' = None) -> 'str | None'\n",
      " |      Convert from serialized representation of a file (base64) to a human-friendly\n",
      " |      version (string filepath). Optionally, save the file to the directory specified by save_dir\n",
      " |      Parameters:\n",
      " |          x: Base64 representation of image to deserialize into a string filepath\n",
      " |          save_dir: Path to directory to save the deserialized image to\n",
      " |          root_url: Ignored\n",
      " |          hf_token: Ignored\n",
      " |  \n",
      " |  example_inputs(self) -> 'dict[str, Any]'\n",
      " |      The example inputs for this component as a dictionary whose values are example inputs compatible with this component.\n",
      " |      Keys of the dictionary are: raw, serialized\n",
      " |  \n",
      " |  serialize(self, x: 'str | None', load_dir: 'str | Path' = '') -> 'str | None'\n",
      " |      Convert from human-friendly version of a file (string filepath) to a serialized\n",
      " |      representation (base64).\n",
      " |      Parameters:\n",
      " |          x: String path to file to serialize\n",
      " |          load_dir: Path to directory containing x\n",
      " |  \n",
      " |  serialized_info(self)\n",
      " |      The typing information for this component as a dictionary whose values are a list of 2 strings: [Python type, language-agnostic description].\n",
      " |      Keys of the dictionary are: raw_input, raw_output, serialized_input, serialized_output\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gradio_client.serializing.Serializable:\n",
      " |  \n",
      " |  input_api_info(self) -> 'tuple[str, str]'\n",
      " |      # For backwards compatibility\n",
      " |  \n",
      " |  output_api_info(self) -> 'tuple[str, str]'\n",
      " |      # For backwards compatibility\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(gr.templates.Sketchpad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math-copilot-qD_LKc1s-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
